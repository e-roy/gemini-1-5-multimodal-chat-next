# Gemini 1.5 Multimodel Chat / Next js

This project is a simple web app for using the Google Gemini 1.5 model.

User input can be either text, image or audio through the client's microphone.

### I created this to help others building apps with Gemini 1.5. If you find it helpful, please give a ‚≠ê

## Getting Started

Visit [Google AI](https://ai.google.dev/) for your AI API key

Create a `.env.local` file and add your api key

```
GOOGLE_API_KEY=

```

First, install packages:

```bash
yarn
```

Then, run the development server:

```bash
yarn dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

Add at least one image to use Vision.

## Learn More

To learn more about OpenAI API
[Documentation](https://platform.openai.com/docs/overview)

To learn more about uploadthing storage API
[Documentation](https://docs.uploadthing.com/)

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.
